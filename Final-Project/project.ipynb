{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mammo_poli_Resnet50.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JipBD-eIlOAT",
        "outputId": "768cf201-2b4d-4141-e8c0-780e0509f1fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nCJghD4lQ5k"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import copy\n",
        "import os\n",
        "from PIL import ImageFile\n",
        "from PIL import Image\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_yff-d_lS37",
        "outputId": "784a1bbd-e938-453d-ec80-417004f3a92e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Learning rate parameters\n",
        "BASE_LR = 0.001\n",
        "EPOCH_DECAY = 30 # number of epochs after which the Learning rate is decayed exponentially.\n",
        "DECAY_WEIGHT = 0.1 # factor by which the learning rate is reduced.\n",
        "\n",
        "\n",
        "# DATASET INFO\n",
        "NUM_CLASSES = 2 # set the number of classes in your dataset\n",
        "DATA_DIR = '/content/drive/My Drive/progetto/MAMMO_MBONLY' # to run with the sample dataset, just set to 'hymenoptera_data'\n",
        "\n",
        "# DATALOADER PROPERTIES\n",
        "BATCH_SIZE = 10 # Set as high as possible. If you keep it too high, you'll get an out of memory error.\n",
        "\n",
        "\n",
        "### GPU SETTINGS\n",
        "#CUDA_DEVICE = 0 # Enter device ID of your gpu if you want to run on gpu. Otherwise neglect.\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device: %s'%device)\n",
        "GPU_MODE = 1 # set to 1 if want to run on gpu.\n",
        "\n",
        "use_gpu = 0\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ntz57OlClVlO"
      },
      "source": [
        "# If you want to read more, transforms is a function from torchvision, and you can go read more here - http://pytorch.org/docs/master/torchvision/transforms.html\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        #transforms.ToPILImage(),\n",
        "        #transforms.Resize(224),\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        #transforms.Grayscale(3),\n",
        "        #transforms.ColorJitter( contrast=0.5),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        #transforms.ToPILImage(),                        \n",
        "        #transforms.RandomResizedCrop(224),\n",
        "        transforms.Resize(224),\n",
        "        transforms.CenterCrop(224),\n",
        "        #transforms.ColorJitter(brightness=0, contrast=1, saturation=0.7, hue=0),\n",
        "        #transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWrbfWQflZHu"
      },
      "source": [
        "data_dir = DATA_DIR\n",
        "dsets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n",
        "         for x in ['train', 'val']}\n",
        "dset_loaders = {x: torch.utils.data.DataLoader(dsets[x], batch_size=BATCH_SIZE,\n",
        "                                               shuffle=True, num_workers=0\n",
        "                                               )\n",
        "                for x in ['train', 'val']}\n",
        "dset_sizes = {x: len(dsets[x]) for x in ['train', 'val']}\n",
        "dset_classes = dsets['train'].classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sSLBljAokJE"
      },
      "source": [
        "def update_lr(optimizer, lr):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKKyCaScO3HI",
        "outputId": "f7610e31-3a5b-45ce-8360-73e2342f71bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Run the functions and save the best model in the function model_ft.\n",
        "num_epochs = 30\n",
        "#TRAINING GALASSO\n",
        "\n",
        "#RESNET\n",
        "# model = models.resnet50(pretrained=True)\n",
        "# num_ftrs = model.fc.in_features\n",
        "# model.fc = nn.Linear(num_ftrs, NUM_CLASSES)\n",
        "# model.to(device)\n",
        "\n",
        "# #LOAD A MODEL\n",
        "checkpoint = torch.load('/content/drive/My Drive/progetto/mask_rectangle_best_resnet50.pth')\n",
        "#model = torch.load('/content/drive/My Drive/progetto/TOMO_resnet50.pth')\n",
        "model = models.resnet50(pretrained=True)    \n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, NUM_CLASSES)  # make the change\n",
        "model.load_state_dict(checkpoint)\n",
        "model.to(device)\n",
        "\n",
        "#VGG-16\n",
        "\n",
        "# model = models.vgg16_bn(pretrained=False)\n",
        "# num_features = model.classifier[6].in_features\n",
        "# features = list(model.classifier.children())[:-1] # Remove last layer\n",
        "# features.extend([nn.Linear(num_features, NUM_CLASSES)]) # Add our layer with 4 outputs\n",
        "# model.classifier = nn.Sequential(*features)\n",
        "# model.to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.RMSprop(model.parameters(), lr=0.0001)\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=DECAY_WEIGHT)\n",
        "early_epoch = 0 \n",
        "# Train the model\n",
        "lr = 0.0001\n",
        "total_step = len(dset_loaders['train'])\n",
        "loss_train = []\n",
        "loss_val = []\n",
        "best_accuracy = None\n",
        "accuracy_val = []\n",
        "best_model = model # get a new instance\n",
        "for epoch in range(num_epochs):\n",
        "    print('Epoch:', epoch+1)\n",
        "    \n",
        "    model.train()\n",
        "\n",
        "    loss_iter = 0\n",
        "    for i, (images, labels) in enumerate(dset_loaders['train']):\n",
        "        # Move tensors to the configured device\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_iter += loss.item()\n",
        "\n",
        "        if (i+1) % 10 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
        "\n",
        "    loss_train.append(loss_iter/(len(dset_loaders['train'])*BATCH_SIZE))\n",
        "\n",
        "\n",
        "    # Code to update the lr\n",
        "    lr *= 0.99\n",
        "    update_lr(optimizer, lr)\n",
        "    \n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        loss_iter = 0\n",
        "        for images, labels in dset_loaders['val']:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            #print(predicted)\n",
        "\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            \n",
        "            loss = criterion(outputs, labels)\n",
        "            loss_iter += loss.item()\n",
        "            \n",
        "        loss_val.append(loss_iter/(len(dset_loaders['val'])*BATCH_SIZE))\n",
        "\n",
        "        accuracy = 100 * correct / total\n",
        "        accuracy_val.append(accuracy)\n",
        "        \n",
        "        print('Validataion accuracy is: {} %'.format(accuracy))\n",
        "        #################################################################################\n",
        "        # TODO: Q2.b Use the early stopping mechanism from previous questions to save   #\n",
        "        # the model with the best validation accuracy so-far (use best_model).          #\n",
        "        #################################################################################\n",
        "\n",
        "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "        if epoch >=3 and accuracy > max(accuracy_val[:-1]):\n",
        "            best_model = copy.deepcopy(model)\n",
        "            early_epoch = epoch\n",
        "        \n",
        "        if epoch == num_epochs - 1:\n",
        "            print(f'\\nEarly Stopping at the epoch: {early_epoch+1} with accuracy: {accuracy_val[early_epoch]:.2f} and acc: {100 * accuracy_val[early_epoch]:.2f}%')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1\n",
            "Epoch [1/30], Step [10/18], Loss: 0.6320\n",
            "Validataion accuracy is: 66.17647058823529 %\n",
            "Epoch: 2\n",
            "Epoch [2/30], Step [10/18], Loss: 0.7516\n",
            "Validataion accuracy is: 44.11764705882353 %\n",
            "Epoch: 3\n",
            "Epoch [3/30], Step [10/18], Loss: 0.6398\n",
            "Validataion accuracy is: 47.05882352941177 %\n",
            "Epoch: 4\n",
            "Epoch [4/30], Step [10/18], Loss: 0.5939\n",
            "Validataion accuracy is: 45.588235294117645 %\n",
            "Epoch: 5\n",
            "Epoch [5/30], Step [10/18], Loss: 0.7881\n",
            "Validataion accuracy is: 45.588235294117645 %\n",
            "Epoch: 6\n",
            "Epoch [6/30], Step [10/18], Loss: 0.9301\n",
            "Validataion accuracy is: 36.76470588235294 %\n",
            "Epoch: 7\n",
            "Epoch [7/30], Step [10/18], Loss: 0.6637\n",
            "Validataion accuracy is: 35.294117647058826 %\n",
            "Epoch: 8\n",
            "Epoch [8/30], Step [10/18], Loss: 0.6466\n",
            "Validataion accuracy is: 63.23529411764706 %\n",
            "Epoch: 9\n",
            "Epoch [9/30], Step [10/18], Loss: 0.5908\n",
            "Validataion accuracy is: 57.35294117647059 %\n",
            "Epoch: 10\n",
            "Epoch [10/30], Step [10/18], Loss: 0.5307\n",
            "Validataion accuracy is: 67.6470588235294 %\n",
            "Epoch: 11\n",
            "Epoch [11/30], Step [10/18], Loss: 0.8487\n",
            "Validataion accuracy is: 33.8235294117647 %\n",
            "Epoch: 12\n",
            "Epoch [12/30], Step [10/18], Loss: 0.7924\n",
            "Validataion accuracy is: 66.17647058823529 %\n",
            "Epoch: 13\n",
            "Epoch [13/30], Step [10/18], Loss: 0.6005\n",
            "Validataion accuracy is: 58.8235294117647 %\n",
            "Epoch: 14\n",
            "Epoch [14/30], Step [10/18], Loss: 0.5590\n",
            "Validataion accuracy is: 61.76470588235294 %\n",
            "Epoch: 15\n",
            "Epoch [15/30], Step [10/18], Loss: 0.4483\n",
            "Validataion accuracy is: 58.8235294117647 %\n",
            "Epoch: 16\n",
            "Epoch [16/30], Step [10/18], Loss: 0.5296\n",
            "Validataion accuracy is: 60.294117647058826 %\n",
            "Epoch: 17\n",
            "Epoch [17/30], Step [10/18], Loss: 0.6700\n",
            "Validataion accuracy is: 44.11764705882353 %\n",
            "Epoch: 18\n",
            "Epoch [18/30], Step [10/18], Loss: 0.7984\n",
            "Validataion accuracy is: 58.8235294117647 %\n",
            "Epoch: 19\n",
            "Epoch [19/30], Step [10/18], Loss: 0.5952\n",
            "Validataion accuracy is: 61.76470588235294 %\n",
            "Epoch: 20\n",
            "Epoch [20/30], Step [10/18], Loss: 0.4919\n",
            "Validataion accuracy is: 52.94117647058823 %\n",
            "Epoch: 21\n",
            "Epoch [21/30], Step [10/18], Loss: 0.6111\n",
            "Validataion accuracy is: 55.88235294117647 %\n",
            "Epoch: 22\n",
            "Epoch [22/30], Step [10/18], Loss: 0.6355\n",
            "Validataion accuracy is: 58.8235294117647 %\n",
            "Epoch: 23\n",
            "Epoch [23/30], Step [10/18], Loss: 0.7843\n",
            "Validataion accuracy is: 41.1764705882353 %\n",
            "Epoch: 24\n",
            "Epoch [24/30], Step [10/18], Loss: 0.4760\n",
            "Validataion accuracy is: 54.411764705882355 %\n",
            "Epoch: 25\n",
            "Epoch [25/30], Step [10/18], Loss: 0.5322\n",
            "Validataion accuracy is: 54.411764705882355 %\n",
            "Epoch: 26\n",
            "Epoch [26/30], Step [10/18], Loss: 0.3819\n",
            "Validataion accuracy is: 48.529411764705884 %\n",
            "Epoch: 27\n",
            "Epoch [27/30], Step [10/18], Loss: 0.4434\n",
            "Validataion accuracy is: 54.411764705882355 %\n",
            "Epoch: 28\n",
            "Epoch [28/30], Step [10/18], Loss: 0.5167\n",
            "Validataion accuracy is: 66.17647058823529 %\n",
            "Epoch: 29\n",
            "Epoch [29/30], Step [10/18], Loss: 0.4276\n",
            "Validataion accuracy is: 50.0 %\n",
            "Epoch: 30\n",
            "Epoch [30/30], Step [10/18], Loss: 0.5401\n",
            "Validataion accuracy is: 54.411764705882355 %\n",
            "\n",
            "Early Stopping at the epoch: 10 with accuracy: 67.65 and acc: 6764.71%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0rR3sVmnnX1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBP2Vj4CGT4Q",
        "outputId": "f2122e43-a328-4d82-c207-a76364aee95d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "for data in dset_loaders['val']:\n",
        "  image,lab = data\n",
        "  print(lab)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "tensor([0, 0, 0, 0, 0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQeO_YJysyg_"
      },
      "source": [
        "#filename_pth = '/content/drive/My Drive/progetto/Mammo_poli_resnet_notpretrained.pth'\n",
        "#torch.save(model.state_dict(), filename_pth)\n",
        "\n",
        "import pandas as pd\n",
        "df = pd.DataFrame({'epoch' : range(len(loss_train)), \n",
        "                       'loss_train':loss_train,\n",
        "                       'loss_val':loss_val,\n",
        "                       'accuracy_val': accuracy_val})\n",
        "    \n",
        "df.to_csv('/content/drive/My Drive/progetto/Mammo_poli_transfer_data.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udLn4jmI3MaV"
      },
      "source": [
        "# If you want to read more, transforms is a function from torchvision, and you can go read more here - http://pytorch.org/docs/master/torchvision/transforms.html\n",
        "data_transforms_test = {\n",
        "    'val': transforms.Compose([\n",
        "        #transforms.ToPILImage(),\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        #transforms.ColorJitter(brightness=0, contrast=1, saturation=0.7, hue=0),\n",
        "        #transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "   \n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vyOeaS53T1c"
      },
      "source": [
        "data_dir = '/content/drive/My Drive/progetto/TOMO_train_val'\n",
        "dsets = {'val': datasets.ImageFolder(os.path.join(data_dir, 'val'), data_transforms_test['val'])\n",
        "         }\n",
        "dset_loaders_test = {'val': torch.utils.data.DataLoader(dsets['val'], batch_size=120,\n",
        "                                               shuffle=True, num_workers=0\n",
        "                                               )}\n",
        "              \n",
        "#dset_sizes = {x: len(dsets[x]) for x in ['train', 'val']}\n",
        "#dset_classes = dsets['t'].classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlkZpQMj3zok",
        "outputId": "504e244f-6bcf-4f83-f7be-31c5fc48c92e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = torch.load('/content/drive/My Drive/progetto/TOMO_resnet50.pth')\n",
        "#model = models.resnet50(pretrained=True)    \n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, NUM_CLASSES)  # make the change\n",
        "# model.load_state_dict(checkpoint)\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vb_xEn6X3VrF"
      },
      "source": [
        "with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        loss_iter = 0\n",
        "        for images, labels in dset_loaders_test['val']:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Zug5Wi36-4L",
        "outputId": "1cf2c0bd-ad46-4943-9781-d2fd0ef45481",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "correct"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mn7jXy8W3Zy-",
        "outputId": "44616cb8-315c-4648-ce20-1dd4821986a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "acc = 100 * correct / total\n",
        "print(acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "43.333333333333336\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}